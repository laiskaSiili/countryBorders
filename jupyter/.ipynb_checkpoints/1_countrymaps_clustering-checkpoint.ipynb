{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1_countrymaps_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "The polygon geometries of all countries are clustered in a distance based manner by using an iterative clustering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment setup\n",
    "For dependency handling, create a new virtual environment from the requirements.txt, then add it as a jupyter kernel to use it in this notebook:\n",
    "1. Assuming you have virtualenv wrapper, create a new virtual environment using *mkvirtualenv venv_name*.\n",
    "2. Enter virtual environment using *workon venv_name*.\n",
    "3. Install dependencies from requirements file using *pip install -r requirements.txt*.\n",
    "4. Install jupyter kernel using *ipython kernel install --user --name=venv_name*.\n",
    "5. Select newly installed kernel in jupyert notebook via *Kernel -> Change kernel*.\n",
    "6. (optional) To uninstall the kernel later, use *jupyter kernelspec uninstall kernel_name*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden depedency of geopandas: descartes\n",
    "import geopandas as gpd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Data\n",
    "Datasets are from [naturalearthdata](https://www.naturalearthdata.com/downloads/10m-cultural-vectors/) with public license, meaning they are free to use for everybody. For countries the dataset **Admin 0 â€“ Countries** is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries_4326 = gpd.read_file('data/ne_50m_admin_0_countries/ne_50m_admin_0_countries.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II) Algorithm\n",
    "The following algorithm performs a distance based clustering on the polygons of each country in order to facilitate plotting. An iterative approach is applied, whereby in a first step the largest polygon of a country is chosen as so called *primary*. A buffer is applied around the primary and all polygons of the same country with their centroid within the buffer are selected and merged with the primary using unary_union, forming a new, larger primary. This step is repeated until there are no new polygons found to be merged. The primary is then saved in the list of country parts. Out of the remaining polygons of the country, the largest is again chosen as the new starting point and the whole process is repeated until no more polygons of the country are left. This procedure is performed on every country.\n",
    "### Ouput\n",
    "A list of geometry groups, of which each describes a single group generated by the algorithm. Each country therefore has 1 or several list entries belonging to it. Each list entry contains the following:\n",
    "- The country name and ISO signature it belongs to.\n",
    "- A polygon or multipolygon geometry.\n",
    "- A boolean indicating whether this entry is the main geometry, meaning it is the largest geometry group of the country.\n",
    "- The total number of geometry groups that the country consists of. This is an auxilliary information used in the following  annotation step to only process countries that consist of multiple geometry groups.\n",
    "- A name that corresponds to the polygon group. It is here assumed that the group with the largest area is the country. All other groups are labelled \"Unknown X\" with X being a numbering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo Algorithm\n",
    "0. Read countries and project to EPSG 3857 (pseudomercator).\n",
    "1. Iterate over all countries, and perform the following...\n",
    "2. If the country consists of a single geometry, early exit because no clustering is necessary.\n",
    "3. Split the country geometry into single polygons.\n",
    "4. Find largest polygon, create a buffer around it and use the resulting bounding box to find all polygons that have their centroid within and merge all of them into a multipolygon.\n",
    "5. Break if no additional polygon was added to the primary in this step.\n",
    "6. Remove the resulting multipolygon (primary) from the dataset and add it to a geometry list.\n",
    "7. Convert the resulting geometries from the geometry list back to EPSG 4326 and add them to the result list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_list = []\n",
    "min_x = -20037508.342789\n",
    "max_x = 20037508.342789\n",
    "dissolve_buffer_m = 500000\n",
    "# 0. Read countries and project to EPSG 3857 (pseudomercator).\n",
    "# Project layer to EPSG 3857, because shapely only supports buffer calculations on cartesian plane.\n",
    "all_countries_3857 = all_countries_4326.to_crs(epsg=3857)\n",
    "#all_countries_3857['geometry'] = all_countries_3857.translate(xoff=translation_offset)\n",
    "# 1. Iterate over all countries, and perform the following...\n",
    "for index, country in all_countries_3857.iterrows():\n",
    "    geometry_groups = []\n",
    "    geoseries = []\n",
    "    if country.geometry.geom_type == 'Polygon':\n",
    "        # Process single polygon\n",
    "        # 2. If the country consists of a single geometry, early exit because no clustering is necessary.\n",
    "        nr_iterations_list = [1]\n",
    "        geometry_groups.append(country.geometry)\n",
    "    else:\n",
    "        # Process multipolygon\n",
    "        # 3. Split the country geometry into single polygons.\n",
    "        country_parts = gpd.GeoDataFrame({'geometry': country.geometry}, crs=all_countries_3857.crs)\n",
    "        nr_iterations = 0\n",
    "        nr_iterations_list = []\n",
    "        while country_parts.shape[0] > 0:\n",
    "            sum_within_before = 0\n",
    "            # 4. Find largest polygon, create a buffer around it and use the resulting bounding box \n",
    "            # to find all polygons that have their centroid within and merge all of them into a multipolygon.\n",
    "            primary = country_parts[country_parts.area == country_parts.area.max()].unary_union\n",
    "            while True:\n",
    "                nr_iterations += 1\n",
    "                primary_buffered_bbox = primary.buffer(distance=dissolve_buffer_m).envelope\n",
    "                within_primary_bool = country_parts.centroid.within(primary_buffered_bbox)\n",
    "                primary = country_parts.loc[within_primary_bool].unary_union\n",
    "                sum_within = sum(within_primary_bool)\n",
    "                if sum_within == sum_within_before:\n",
    "                    # 5. Break if no additional polygon was added to the primary in this step.\n",
    "                    nr_iterations_list.append(nr_iterations)\n",
    "                    nr_iterations = 0\n",
    "                    break\n",
    "                sum_within_before = sum_within\n",
    "            # 6. Remove the resulting multipolygon (primary) from the dataset and add it to a geometry list.\n",
    "            country_parts = country_parts.loc[within_primary_bool == False]\n",
    "            geometry_groups.append(primary)\n",
    "    print(f'Processed: {country[\"ADMIN\"]} ({country[\"ADM0_A3\"]}), iterations: {\",\".join(str(x) for x in nr_iterations_list)}')\n",
    "\n",
    "    # 7. Convert the resulting geometries from the geometry list back to EPSG 4326 and add them to the result list.\n",
    "    # Create a list of country parts that allows easy navigation for subsequent name entering. Assume largest Polygon is has country name as title.\n",
    "    #geometry_groups = [gpd.GeoSeries(geom, crs=3857).translate(xoff=-translation_offset).to_crs(epsg=4326).geometry for geom in geometry_groups]\n",
    "    geometry_groups = [gpd.GeoSeries(geom, crs=3857).to_crs(epsg=4326).geometry for geom in geometry_groups]\n",
    "    nr_parts = len(geometry_groups)\n",
    "    country_list.append({\n",
    "        'country': country['ADMIN'],\n",
    "        'main': True,\n",
    "        'nr_parts': nr_parts,\n",
    "        'ADM0_A3': country['ADM0_A3'],\n",
    "        'name': country['ADMIN'],\n",
    "        'geometry': geometry_groups.pop(0),\n",
    "    })\n",
    "    for i, geometry in enumerate(sorted(geometry_groups, key=lambda x:x.area.iloc[0], reverse=True)):\n",
    "        country_list.append({\n",
    "            'country': country['ADMIN'],\n",
    "            'main': False,\n",
    "            'nr_parts': nr_parts,\n",
    "            'ADM0_A3': country['ADM0_A3'],\n",
    "            'name': f'Unknown {i}',\n",
    "            'geometry': geometry\n",
    "        })\n",
    "pickle.dump(country_list, open('country_list.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "country",
   "language": "python",
   "name": "country"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
