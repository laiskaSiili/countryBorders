{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country maps prototype V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "The polygon geometries of all countries are clustered in a distance based manner by using a 2-pass algorithm. The resulting list of geometry group is then visualized in a ipyleaflet map, which allows to label the groups. The list is continuously saved as a pickle object, therefore saving any changes made to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "For dependency handling, create a new virtual environment from the requirements.txt, then add it as a jupyter kernel to use it in this notebook:\n",
    "1. Assuming you have virtualenv wrapper, create a new virtual environment using *mkvirtualenv venv_name*.\n",
    "2. Enter virtual environment using *workon venv_name*.\n",
    "3. Install dependencies from requirements file using *pip install -r requirements.txt*.\n",
    "4. Install jupyter kernel using *ipython kernel install --user --name=venv_name*.\n",
    "5. Select newly installed kernel in jupyert notebook via *Kernel -> Change kernel*.\n",
    "6. (optional) To uninstall the kernel later, use *jupyter kernelspec uninstall kernel_name*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden depedency of geopandas: descartes\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from ipyleaflet import *\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Datasets\n",
    "Datasets are from [naturalearthdata](https://www.naturalearthdata.com/downloads/10m-cultural-vectors/) with public license, meaning they are free to use for everybody. For countries the dataset **Admin 0 â€“ Countries** is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries_4326 = gpd.read_file('data/ne_50m_admin_0_countries/ne_50m_admin_0_countries.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "The following algorithm groups performs a distance based clustering on the polygons of each country in order to facilitate plotting. A two pass approach is applied, whereby in the first pass all polygons within a smaller radius around the largest polygon are grouped together. In a second pass, all polygons within a larger radius around the resulting group of pass 1 are also merged together. All merged polygons from pass1 and pass2 are then removed and the process is repeated until no more polygons are left. The two pass approach aims at reducing artifacts that arise when a country consists of several large polygons in close distance and some smaller polygon groups further away (e.g. Japan).\n",
    "### Ouput\n",
    "A list of dictionaries, of which each describes a single group generated by the algorithm. Each country therefore has 1 or several dictionary objects in the list belonging to it. Each dictionary contains the following:\n",
    "- The country name and ISO signature that this dictionary belongs to.\n",
    "- A polygon or multipolygon geometry.\n",
    "- A name that corresponds to the polygon group. It is here assumed that the group with the largest area is the country. All other groups are labelled \"Unknown X\" with X being a numbering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo Algorithm\n",
    "0. Read countries and project to EPSG 3857 (pseudomercator).\n",
    "1. Iterate over all countries, and perform the following...\n",
    "2. Split the country geometry into single polygons.\n",
    "3. Pass 1: Find largest polygon, create a buffer around it and use the resulting bounding box to find all polygons that have their centroid within and merge all of them into a multipolygon.\n",
    "4. Pass 2: Using the resulting geometry of step 3, create a larger buffer and again find all polygons with their centroid within the resulting bounding box and merge them.\n",
    "5. Remove the resulting multipolygon from the two passes from the dataset and add it to a geometry list.\n",
    "6. If there still are polygons left, go to step 3.\n",
    "7. If the country consists of a single polygon, skip steps 3-6 and directly add it to the geometry list.\n",
    "8. Convert the resulting geometries from the geometry list back to EPSG 4326 and add them to the result list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_list = []\n",
    "dissolve_buffer_m_step1 = 500000\n",
    "dissolve_buffer_m_step2 = 1000000\n",
    "# 0. Read countries and project to EPSG 3857 (pseudomercator).\n",
    "# Project layer to EPSG 3857, because shapely only supports buffer calculations on cartesian plane.\n",
    "all_countries_3857 = all_countries_4326.to_crs(epsg=3857)\n",
    "# 1. Iterate over all countries, and perform the following...\n",
    "for index, country in all_countries_3857.iterrows():\n",
    "    print(f'Processing: {country[\"ADMIN\"]} ({country[\"ISO_A3\"]})')\n",
    "    geometry_groups = []\n",
    "    geoseries = []\n",
    "    if country.geometry.geom_type == 'Polygon':\n",
    "        # Process single polygon\n",
    "        # 7. If the country consists of a single polygon, skip steps 3-6 and directly add it to the geometry list.\n",
    "        geometry_groups.append(country.geometry)\n",
    "    else:\n",
    "        # Process multipolygon\n",
    "        # 2. Split the country geometry into single polygons.\n",
    "        country_parts = gpd.GeoDataFrame({'geometry': country.geometry}, crs=all_countries_3857.crs)\n",
    "        while country_parts.shape[0] > 0:\n",
    "            # 3. Pass 1: Find largest polygon, create a buffer around it and use the resulting bounding box to find all polygons that have their centroid within and merge all of them into a multipolygon.\n",
    "            primary_step1 = country_parts[country_parts.area == country_parts.area.max()]\n",
    "            primary_buffered_bbox_step1 = primary_step1.buffer(distance=dissolve_buffer_m_step1).envelope.iloc[0]\n",
    "            within_primary_bool_step1 = country_parts.centroid.within(primary_buffered_bbox_step1)\n",
    "            merged_primary_step1 = country_parts.loc[within_primary_bool_step1].unary_union\n",
    "            if country_parts.shape[0] == 0:\n",
    "                # If no more geometries are left, add primary from step 1 and break.\n",
    "                geometry_groups.append(merged_primary_step1)\n",
    "                break\n",
    "            # 4. Pass 2: Using the resulting geometry of step 3, create a larger buffer and again find all polygons with their centroid within the resulting bounding box and merge them.\n",
    "            primary_buffered_bbox_step2 = merged_primary_step1.buffer(distance=dissolve_buffer_m_step2).envelope\n",
    "            within_primary_bool_step2 = country_parts.centroid.within(primary_buffered_bbox_step2)\n",
    "            merged_primary_step2 = country_parts.loc[within_primary_bool_step2].unary_union\n",
    "            # 5. Remove the resulting multipolygon from the two passes from the dataset and add it to a geometry list.\n",
    "            country_parts = country_parts.loc[within_primary_bool_step2 == False]\n",
    "            # APPEND PRIMARY FOUND IN PASS 2\n",
    "            geometry_groups.append(merged_primary_step2)\n",
    "            # 6. If there still are polygons left, go to step 3.\n",
    "\n",
    "    # 8. Convert the resulting geometries from the geometry list back to EPSG 4326 and add them to the result list.\n",
    "    # Create a list of country parts that allows easy navigation for subsequent name entering. Assume largest Polygon is has country name as title.\n",
    "    geometry_groups = [gpd.GeoSeries(geom, crs=3857).to_crs(epsg=4326).geometry for geom in geometry_groups]\n",
    "    country_list.append({\n",
    "        'country': country['ADMIN'],\n",
    "        'ISO_A3': country['ISO_A3'],\n",
    "        'name': country['ADMIN'],\n",
    "        'geometry': geometry_groups.pop(0),\n",
    "    })\n",
    "    for i, geometry in enumerate(geometry_groups):\n",
    "        country_list.append({\n",
    "            'country': country['ADMIN'],\n",
    "            'ISO_A3': country['ISO_A3'],\n",
    "            'name': f'Unknown {i}',\n",
    "            'geometry': geometry\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation of country parts\n",
    "The following two cells intiialize an ipyleaflet map, that interactively lets you annotate the country parts. use the following controls:\n",
    "- Zoom via slider OR **mouse wheel**.\n",
    "- Click the **Next** and **Previous** buttons to jump from country part to country part.\n",
    "- The **Country** textfield shows you to what country the current country prt belongt to. It is not editable.\n",
    "- Enter a fitting name (e.g. Alaska, Azores) for the country part into the textfield **Name** in the upper right.\n",
    "- **Note:** Each time you navigate from one place to another, your changes are automatically saved in memory as well as a pickle object of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Map(center=(0,0), zoom=9, scroll_wheel_zoom=True, zoom_control=False, basemap=basemaps.Esri.WorldStreetMap)\n",
    "marker = Marker(location=(0,0), draggable=False)\n",
    "m.add_layer(marker)\n",
    "\n",
    "zoom_slider = widgets.IntSlider(description='Zoom level:', min=0, max=15, value=7)\n",
    "widgets.jslink((zoom_slider, 'value'), (m, 'zoom'))\n",
    "widget_control_zoom = WidgetControl(widget=zoom_slider, position='topleft')\n",
    "m.add_control(widget_control_zoom)\n",
    "\n",
    "country_text = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='',\n",
    "    description='Country:',\n",
    "    disabled=True,\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "text_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='',\n",
    "    description='Name:',\n",
    "    disabled=False,\n",
    "    layout={'width': '500px'}\n",
    ")\n",
    "\n",
    "goto_next = widgets.Button(\n",
    "    description='Next',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Next geometry',\n",
    "    icon=''\n",
    ")\n",
    "\n",
    "goto_pevious = widgets.Button(\n",
    "    description='Previous',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Prevous geometry',\n",
    "    icon=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "def goto_index(index):\n",
    "    text_input.value = country_list[index]['name']\n",
    "    country_text.value = country_list[index]['country']\n",
    "    centroid = country_list[index]['geometry'].centroid.iloc[0]\n",
    "    center = (centroid.y, centroid.x)\n",
    "    m.center = center\n",
    "    marker.location = center\n",
    "    \n",
    "def next_clicked(button):\n",
    "    global index\n",
    "    country_list[index]['name'] = text_input.value\n",
    "    pickle.dump(country_list, open('country_list.p', 'wb'))\n",
    "    index += 1\n",
    "    if index == len(country_list):\n",
    "        index = 0\n",
    "    goto_index(index)\n",
    "    \n",
    "def previous_clicked(button):\n",
    "    global index\n",
    "    country_list[index]['name'] = text_input.value\n",
    "    pickle.dump(country_list, open('country_list.p', 'wb'))\n",
    "    index -= 1\n",
    "    if index < 0:\n",
    "        index = len(country_list) - 1\n",
    "    goto_index(index)\n",
    "    \n",
    "goto_next.on_click(next_clicked)\n",
    "goto_pevious.on_click(previous_clicked)\n",
    "\n",
    "widget_control_country = WidgetControl(widget=country_text, position='topright')\n",
    "m.add_control(widget_control_country)\n",
    "widget_control_input = WidgetControl(widget=text_input, position='topright')\n",
    "m.add_control(widget_control_input)\n",
    "widget_control_next = WidgetControl(widget=goto_next, position='bottomright')\n",
    "m.add_control(widget_control_next)\n",
    "widget_control_previous = WidgetControl(widget=goto_pevious, position='bottomleft')\n",
    "m.add_control(widget_control_previous)\n",
    "\n",
    "goto_index(index)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell above should show a map. If this is not the case, try to reboot your jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "country",
   "language": "python",
   "name": "country"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
